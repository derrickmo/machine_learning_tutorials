{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01 \u2014 Mathematical & Programming Foundations\n",
    "## 1-01: Python, NumPy & Tensor Speed\n",
    "\n",
    "**Objective:** Understand why vectorized computation is essential for ML and learn the foundations of NumPy and PyTorch tensor operations.\n",
    "\n",
    "**Prerequisites:** None (entry point to the course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0 \u2014 Setup & Prerequisites\n",
    "\n",
    "This notebook covers the performance gap between pure Python loops, NumPy vectorized operations, and PyTorch tensor operations. We will benchmark identical computations across all three approaches, explore broadcasting rules, and examine memory layout concepts that determine computational efficiency.\n",
    "\n",
    "**Prerequisites:** None \u2014 this is the entry point to the entire 200-topic course."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Imports \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import time\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Reproducibility \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "SEED = 1103\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Configuration \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "VECTOR_SIZES = [100, 500, 1_000, 5_000, 10_000, 50_000]  # Sizes for vector benchmarks\n",
    "MATRIX_SIZES = [50, 100, 200, 500, 1_000]                 # Sizes for matrix benchmarks\n",
    "NUM_WARMUP = 2                                              # Warmup runs before timing\n",
    "NUM_TIMED_RUNS = 5                                          # Timed runs to average\n",
    "PYTHON_MAX_SIZE = 10_000                                    # Max size for pure Python (too slow beyond)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation\n",
    "\n",
    "We generate random vectors and matrices for benchmarking. Since this notebook focuses on\n",
    "computational speed rather than a specific ML task, all data is synthetic."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate sample data for initial demonstrations\n",
    "DEMO_SIZE = 1_000\n",
    "\n",
    "# Python lists\n",
    "python_vec_a = [random.gauss(0, 1) for _ in range(DEMO_SIZE)]\n",
    "python_vec_b = [random.gauss(0, 1) for _ in range(DEMO_SIZE)]\n",
    "\n",
    "# NumPy arrays\n",
    "numpy_vec_a = np.array(python_vec_a)\n",
    "numpy_vec_b = np.array(python_vec_b)\n",
    "\n",
    "# PyTorch tensors\n",
    "torch_vec_a = torch.tensor(python_vec_a)\n",
    "torch_vec_b = torch.tensor(python_vec_b)\n",
    "\n",
    "print(f\"Python list length:  {len(python_vec_a)}\")\n",
    "print(f\"NumPy array shape:   {numpy_vec_a.shape}, dtype: {numpy_vec_a.dtype}\")\n",
    "print(f\"PyTorch tensor shape: {torch_vec_a.shape}, dtype: {torch_vec_a.dtype}\")\n",
    "print(f\"\\nFirst 5 values (Python):  {python_vec_a[:5]}\")\n",
    "print(f\"First 5 values (NumPy):   {numpy_vec_a[:5]}\")\n",
    "print(f\"First 5 values (PyTorch): {torch_vec_a[:5]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 \u2014 Vectorization from Scratch\n",
    "\n",
    "Vectorization is the technique of replacing explicit Python loops with batch operations\n",
    "implemented in compiled languages (C, C++, Fortran). Libraries like NumPy and PyTorch\n",
    "execute operations on entire arrays in a single call, leveraging:\n",
    "\n",
    "- **Optimized C/C++ backends** (NumPy uses BLAS/LAPACK; PyTorch uses ATen/MKL)\n",
    "- **Contiguous memory layout** enabling CPU cache efficiency\n",
    "- **SIMD instructions** (Single Instruction, Multiple Data) on modern CPUs\n",
    "- **Optional GPU parallelism** (PyTorch tensors can move to CUDA devices)\n",
    "\n",
    "The mathematical operations are identical \u2014 only the *implementation* differs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pure Python Operations\n",
    "\n",
    "We start with three fundamental operations implemented using only Python loops:\n",
    "\n",
    "1. **Dot product:** $\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_i b_i$\n",
    "2. **Element-wise multiplication:** $\\mathbf{c}_i = \\mathbf{a}_i \\times \\mathbf{b}_i$ for all $i$\n",
    "3. **Matrix multiplication:** $(\\mathbf{C})_{ij} = \\sum_{k=1}^{m} (\\mathbf{A})_{ik} (\\mathbf{B})_{kj}$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def python_dot_product(vec_a: list[float], vec_b: list[float]) -> float:\n",
    "    \"\"\"Compute dot product of two vectors using a Python for loop.\n",
    "\n",
    "    Args:\n",
    "        vec_a: First vector as a Python list.\n",
    "        vec_b: Second vector as a Python list.\n",
    "\n",
    "    Returns:\n",
    "        Scalar dot product value.\n",
    "    \"\"\"\n",
    "    assert len(vec_a) == len(vec_b), \"Vectors must have the same length\"\n",
    "    result = 0.0\n",
    "    for idx in range(len(vec_a)):\n",
    "        result += vec_a[idx] * vec_b[idx]\n",
    "    return result\n",
    "\n",
    "\n",
    "def python_elementwise_multiply(vec_a: list[float], vec_b: list[float]) -> list[float]:\n",
    "    \"\"\"Compute element-wise multiplication using a Python for loop.\n",
    "\n",
    "    Args:\n",
    "        vec_a: First vector as a Python list.\n",
    "        vec_b: Second vector as a Python list.\n",
    "\n",
    "    Returns:\n",
    "        Result vector as a Python list.\n",
    "    \"\"\"\n",
    "    assert len(vec_a) == len(vec_b), \"Vectors must have the same length\"\n",
    "    result = [0.0] * len(vec_a)\n",
    "    for idx in range(len(vec_a)):\n",
    "        result[idx] = vec_a[idx] * vec_b[idx]\n",
    "    return result\n",
    "\n",
    "\n",
    "def python_matmul(mat_a: list[list[float]], mat_b: list[list[float]]) -> list[list[float]]:\n",
    "    \"\"\"Compute matrix multiplication using nested Python for loops.\n",
    "\n",
    "    Args:\n",
    "        mat_a: First matrix as a list of lists, shape (rows_a, cols_a).\n",
    "        mat_b: Second matrix as a list of lists, shape (rows_b, cols_b).\n",
    "\n",
    "    Returns:\n",
    "        Result matrix as a list of lists, shape (rows_a, cols_b).\n",
    "    \"\"\"\n",
    "    rows_a = len(mat_a)\n",
    "    cols_a = len(mat_a[0])\n",
    "    rows_b = len(mat_b)\n",
    "    cols_b = len(mat_b[0])\n",
    "    assert cols_a == rows_b, f\"Incompatible shapes: ({rows_a}, {cols_a}) x ({rows_b}, {cols_b})\"\n",
    "\n",
    "    result = [[0.0] * cols_b for _ in range(rows_a)]\n",
    "    for row_idx in range(rows_a):\n",
    "        for col_idx in range(cols_b):\n",
    "            total = 0.0\n",
    "            for k_idx in range(cols_a):\n",
    "                total += mat_a[row_idx][k_idx] * mat_b[k_idx][col_idx]\n",
    "            result[row_idx][col_idx] = total\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test pure Python implementations\n",
    "dot_result_python = python_dot_product(python_vec_a, python_vec_b)\n",
    "elem_result_python = python_elementwise_multiply(python_vec_a[:5], python_vec_b[:5])\n",
    "\n",
    "# Small matrix test\n",
    "small_mat_a = [[1.0, 2.0], [3.0, 4.0]]\n",
    "small_mat_b = [[5.0, 6.0], [7.0, 8.0]]\n",
    "matmul_result_python = python_matmul(small_mat_a, small_mat_b)\n",
    "\n",
    "print(f\"Dot product (Python):           {dot_result_python:.4f}\")\n",
    "print(f\"Element-wise (first 5, Python): {elem_result_python}\")\n",
    "print(f\"Matrix multiply (Python):       {matmul_result_python}\")\n",
    "print(f\"Expected matmul result:         [[19.0, 22.0], [43.0, 50.0]]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 NumPy Vectorized Operations\n",
    "\n",
    "NumPy performs the same operations without explicit Python loops. Under the hood,\n",
    "NumPy dispatches to optimized BLAS (Basic Linear Algebra Subprograms) routines\n",
    "written in C and Fortran. Key functions:\n",
    "\n",
    "- `np.dot(a, b)` \u2014 dot product for 1-D arrays, matrix multiply for 2-D\n",
    "- `np.multiply(a, b)` or `a * b` \u2014 element-wise multiplication\n",
    "- `np.matmul(a, b)` or `a @ b` \u2014 matrix multiplication (preferred over `np.dot` for matrices)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def numpy_dot_product(vec_a: np.ndarray, vec_b: np.ndarray) -> float:\n",
    "    \"\"\"Compute dot product using NumPy.\n",
    "\n",
    "    Args:\n",
    "        vec_a: First vector as a NumPy array.\n",
    "        vec_b: Second vector as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        Scalar dot product value.\n",
    "    \"\"\"\n",
    "    return float(np.dot(vec_a, vec_b))\n",
    "\n",
    "\n",
    "def numpy_elementwise_multiply(vec_a: np.ndarray, vec_b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute element-wise multiplication using NumPy.\n",
    "\n",
    "    Args:\n",
    "        vec_a: First vector as a NumPy array.\n",
    "        vec_b: Second vector as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        Result array.\n",
    "    \"\"\"\n",
    "    return np.multiply(vec_a, vec_b)\n",
    "\n",
    "\n",
    "def numpy_matmul(mat_a: np.ndarray, mat_b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute matrix multiplication using NumPy.\n",
    "\n",
    "    Args:\n",
    "        mat_a: First matrix as a NumPy array.\n",
    "        mat_b: Second matrix as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        Result matrix as a NumPy array.\n",
    "    \"\"\"\n",
    "    return mat_a @ mat_b"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test NumPy implementations and verify against Python results\n",
    "dot_result_numpy = numpy_dot_product(numpy_vec_a, numpy_vec_b)\n",
    "elem_result_numpy = numpy_elementwise_multiply(numpy_vec_a[:5], numpy_vec_b[:5])\n",
    "\n",
    "np_mat_a = np.array(small_mat_a)\n",
    "np_mat_b = np.array(small_mat_b)\n",
    "matmul_result_numpy = numpy_matmul(np_mat_a, np_mat_b)\n",
    "\n",
    "print(f\"Dot product (NumPy):           {dot_result_numpy:.4f}\")\n",
    "print(f\"Element-wise (first 5, NumPy): {elem_result_numpy}\")\n",
    "print(f\"Matrix multiply (NumPy):\\n{matmul_result_numpy}\")\n",
    "\n",
    "# Verify Python and NumPy produce the same results\n",
    "print(f\"\\nDot product match: {np.isclose(dot_result_python, dot_result_numpy)}\")\n",
    "print(f\"Matmul match:      {np.allclose(matmul_result_python, matmul_result_numpy)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 PyTorch Tensor Operations\n",
    "\n",
    "PyTorch tensors provide the same vectorized operations as NumPy, with two key additions:\n",
    "\n",
    "1. **GPU support** \u2014 tensors can be placed on a CUDA device for massive parallelism\n",
    "2. **Automatic differentiation** \u2014 `autograd` tracks operations for gradient computation (covered in Module 5)\n",
    "\n",
    "Key functions:\n",
    "- `torch.dot(a, b)` \u2014 dot product (1-D only)\n",
    "- `torch.mul(a, b)` or `a * b` \u2014 element-wise multiplication\n",
    "- `torch.matmul(a, b)` or `a @ b` \u2014 matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def torch_dot_product(vec_a: torch.Tensor, vec_b: torch.Tensor) -> float:\n",
    "    \"\"\"Compute dot product using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        vec_a: First vector as a PyTorch tensor.\n",
    "        vec_b: Second vector as a PyTorch tensor.\n",
    "\n",
    "    Returns:\n",
    "        Scalar dot product value.\n",
    "    \"\"\"\n",
    "    return float(torch.dot(vec_a, vec_b))\n",
    "\n",
    "\n",
    "def torch_elementwise_multiply(vec_a: torch.Tensor, vec_b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute element-wise multiplication using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        vec_a: First vector as a PyTorch tensor.\n",
    "        vec_b: Second vector as a PyTorch tensor.\n",
    "\n",
    "    Returns:\n",
    "        Result tensor.\n",
    "    \"\"\"\n",
    "    return torch.mul(vec_a, vec_b)\n",
    "\n",
    "\n",
    "def torch_matmul(mat_a: torch.Tensor, mat_b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute matrix multiplication using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        mat_a: First matrix as a PyTorch tensor.\n",
    "        mat_b: Second matrix as a PyTorch tensor.\n",
    "\n",
    "    Returns:\n",
    "        Result matrix as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    return torch.matmul(mat_a, mat_b)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test PyTorch implementations and verify against NumPy\n",
    "dot_result_torch = torch_dot_product(torch_vec_a, torch_vec_b)\n",
    "elem_result_torch = torch_elementwise_multiply(torch_vec_a[:5], torch_vec_b[:5])\n",
    "\n",
    "torch_mat_a = torch.tensor(small_mat_a)\n",
    "torch_mat_b = torch.tensor(small_mat_b)\n",
    "matmul_result_torch = torch_matmul(torch_mat_a, torch_mat_b)\n",
    "\n",
    "print(f\"Dot product (PyTorch):           {dot_result_torch:.4f}\")\n",
    "print(f\"Element-wise (first 5, PyTorch): {elem_result_torch}\")\n",
    "print(f\"Matrix multiply (PyTorch):\\n{matmul_result_torch}\")\n",
    "\n",
    "# Verify all three implementations agree\n",
    "print(f\"\\nAll three dot products match: {np.isclose(dot_result_python, dot_result_numpy) and np.isclose(dot_result_numpy, dot_result_torch)}\")\n",
    "print(f\"NumPy vs PyTorch matmul match: {np.allclose(matmul_result_numpy, matmul_result_torch.numpy())}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.Tensor` vs `torch.tensor`\n",
    "\n",
    "A common source of confusion for beginners:\n",
    "\n",
    "- **`torch.tensor(data)`** \u2014 a *function* that infers dtype from the input data. This is the **recommended** way to create tensors.\n",
    "- **`torch.Tensor(data)`** \u2014 a *class constructor* that always creates `float32` tensors, even if you pass integers.\n",
    "\n",
    "Always prefer `torch.tensor()` for predictable dtype behavior."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demonstrate torch.Tensor vs torch.tensor\n",
    "int_data = [1, 2, 3]\n",
    "\n",
    "tensor_from_class = torch.Tensor(int_data)    # Always float32\n",
    "tensor_from_func = torch.tensor(int_data)     # Infers int64\n",
    "\n",
    "print(f\"torch.Tensor([1,2,3]) -> dtype: {tensor_from_class.dtype}\")\n",
    "print(f\"torch.tensor([1,2,3]) -> dtype: {tensor_from_func.dtype}\")\n",
    "\n",
    "# Explicit dtype control with torch.tensor\n",
    "tensor_float = torch.tensor(int_data, dtype=torch.float32)\n",
    "print(f\"torch.tensor([1,2,3], dtype=float32) -> dtype: {tensor_float.dtype}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Broadcasting Rules\n",
    "\n",
    "Broadcasting is the mechanism by which NumPy and PyTorch handle operations on arrays/tensors\n",
    "with different shapes. Instead of requiring identical shapes, broadcasting *stretches* smaller\n",
    "dimensions to match larger ones \u2014 without actually copying data in memory.\n",
    "\n",
    "**Three rules of broadcasting** (applied from right to left):\n",
    "\n",
    "1. **If the dimensions differ in length, pad the shorter shape with 1s on the left.**\n",
    "   - Example: shape `(3,)` becomes `(1, 3)` when paired with `(2, 3)`.\n",
    "\n",
    "2. **Dimensions of size 1 are stretched to match the other array's size in that dimension.**\n",
    "   - Example: `(1, 3)` is broadcast to `(2, 3)` when paired with `(2, 3)`.\n",
    "\n",
    "3. **Dimensions must either be equal or one of them must be 1. Otherwise, broadcasting fails.**\n",
    "   - Example: `(2, 3)` and `(4, 3)` cannot be broadcast \u2014 dimension 0 is 2 vs 4, and neither is 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Broadcasting example 1: Adding a scalar to a matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "scalar = 10\n",
    "result_scalar = matrix + scalar\n",
    "print(\"Example 1: Matrix + Scalar\")\n",
    "print(f\"Matrix shape: {matrix.shape} + Scalar shape: () -> Result shape: {result_scalar.shape}\")\n",
    "print(f\"Result:\\n{result_scalar}\\n\")\n",
    "\n",
    "# Broadcasting example 2: Adding a row vector to a matrix\n",
    "row_vector = np.array([10, 20, 30])  # shape (3,)\n",
    "result_row = matrix + row_vector\n",
    "print(\"Example 2: Matrix (2,3) + Row Vector (3,)\")\n",
    "print(f\"Matrix shape: {matrix.shape} + Row shape: {row_vector.shape} -> Result shape: {result_row.shape}\")\n",
    "print(f\"Result:\\n{result_row}\\n\")\n",
    "\n",
    "# Broadcasting example 3: Adding a column vector to a matrix\n",
    "col_vector = np.array([[100], [200]])  # shape (2, 1)\n",
    "result_col = matrix + col_vector\n",
    "print(\"Example 3: Matrix (2,3) + Column Vector (2,1)\")\n",
    "print(f\"Matrix shape: {matrix.shape} + Col shape: {col_vector.shape} -> Result shape: {result_col.shape}\")\n",
    "print(f\"Result:\\n{result_col}\\n\")\n",
    "\n",
    "# Broadcasting example 4: Outer product via broadcasting\n",
    "vec_row = np.array([1, 2, 3])          # shape (3,)\n",
    "vec_col = np.array([[10], [20], [30]])  # shape (3, 1)\n",
    "outer_product = vec_col * vec_row       # (3,1) * (3,) -> (3,3)\n",
    "print(\"Example 4: Outer Product via Broadcasting\")\n",
    "print(f\"Col (3,1) * Row (3,) -> shape {outer_product.shape}\")\n",
    "print(f\"Result:\\n{outer_product}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Broadcasting Patterns in ML\n",
    "\n",
    "Broadcasting appears constantly in ML code:\n",
    "\n",
    "| Pattern | Shapes | ML Use Case |\n",
    "|---------|--------|-------------|\n",
    "| Add bias to each sample | `(batch, features) + (features,)` | Linear layer: $\\mathbf{y} = \\mathbf{X}\\mathbf{W} + \\mathbf{b}$ |\n",
    "| Normalize each feature | `(batch, features) - (features,)` | Feature standardization |\n",
    "| Scale per-channel | `(batch, channels, H, W) * (1, channels, 1, 1)` | Batch normalization |\n",
    "| Compute pairwise distances | `(n, 1, d) - (1, m, d)` | k-NN, kernel methods |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ML broadcasting pattern: Adding bias to a batch of samples\n",
    "batch_size = 4\n",
    "num_features = 3\n",
    "\n",
    "# Simulating the output of a linear layer: y = Xw + b\n",
    "batch_data = np.random.randn(batch_size, num_features)\n",
    "bias = np.array([0.5, -0.3, 1.0])  # shape (3,) - one bias per feature\n",
    "\n",
    "# Broadcasting adds bias to every sample in the batch\n",
    "result_with_bias = batch_data + bias\n",
    "print(f\"Batch shape: {batch_data.shape} + Bias shape: {bias.shape}\")\n",
    "print(f\"Result shape: {result_with_bias.shape}\")\n",
    "print(f\"\\nBefore bias (first 2 rows):\\n{batch_data[:2]}\")\n",
    "print(f\"After bias  (first 2 rows):\\n{result_with_bias[:2]}\")\n",
    "\n",
    "# Same pattern works identically in PyTorch\n",
    "torch_batch = torch.tensor(batch_data)\n",
    "torch_bias = torch.tensor(bias)\n",
    "torch_result = torch_batch + torch_bias\n",
    "print(f\"\\nPyTorch result matches NumPy: {np.allclose(result_with_bias, torch_result.numpy())}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Broadcasting pattern: Pairwise distance computation\n",
    "# This is used in k-NN (Module 2) and kernel methods (Module 3)\n",
    "num_points_a = 3\n",
    "num_points_b = 4\n",
    "num_dims = 2\n",
    "\n",
    "points_a = np.random.randn(num_points_a, num_dims)  # shape (3, 2)\n",
    "points_b = np.random.randn(num_points_b, num_dims)  # shape (4, 2)\n",
    "\n",
    "# Expand dimensions for broadcasting: (3,1,2) - (1,4,2) -> (3,4,2)\n",
    "diff = points_a[:, np.newaxis, :] - points_b[np.newaxis, :, :]\n",
    "pairwise_distances = np.sqrt(np.sum(diff ** 2, axis=2))  # shape (3, 4)\n",
    "\n",
    "print(f\"Points A shape:     {points_a.shape}\")\n",
    "print(f\"Points B shape:     {points_b.shape}\")\n",
    "print(f\"Difference shape:   {diff.shape}\")\n",
    "print(f\"Distances shape:    {pairwise_distances.shape}\")\n",
    "print(f\"\\nPairwise distances:\\n{pairwise_distances}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Memory Layout\n",
    "\n",
    "Understanding how tensors are stored in memory is crucial for performance. Two key concepts:\n",
    "\n",
    "**Row-major (C order)** vs **Column-major (Fortran order):**\n",
    "- Row-major: consecutive elements in a row are adjacent in memory (NumPy default, PyTorch default)\n",
    "- Column-major: consecutive elements in a column are adjacent in memory\n",
    "\n",
    "**Strides:** The number of bytes (or elements) to skip in memory to move along each dimension.\n",
    "For a contiguous row-major matrix of shape $(m, n)$, the strides are $(n, 1)$ \u2014 moving down a row\n",
    "skips $n$ elements, moving across a column skips 1 element.\n",
    "\n",
    "**Contiguous vs Non-contiguous:** A tensor is *contiguous* when its elements are laid out in\n",
    "memory in the order implied by its shape and strides. Transpose operations create\n",
    "non-contiguous views, which can impact performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demonstrate strides in NumPy\n",
    "arr_c = np.array([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]], dtype=np.int64)  # Row-major (C order)\n",
    "\n",
    "print(\"Row-major (C order) array:\")\n",
    "print(f\"  Shape:   {arr_c.shape}\")\n",
    "print(f\"  Strides: {arr_c.strides} bytes\")\n",
    "print(f\"  Strides in elements: ({arr_c.strides[0] // arr_c.itemsize}, {arr_c.strides[1] // arr_c.itemsize})\")\n",
    "print(f\"  C-contiguous: {arr_c.flags['C_CONTIGUOUS']}\")\n",
    "print(f\"  F-contiguous: {arr_c.flags['F_CONTIGUOUS']}\")\n",
    "\n",
    "# Column-major (Fortran order)\n",
    "arr_f = np.asfortranarray(arr_c)\n",
    "print(f\"\\nColumn-major (Fortran order) array:\")\n",
    "print(f\"  Same data: {np.array_equal(arr_c, arr_f)}\")\n",
    "print(f\"  Strides: {arr_f.strides} bytes\")\n",
    "print(f\"  C-contiguous: {arr_f.flags['C_CONTIGUOUS']}\")\n",
    "print(f\"  F-contiguous: {arr_f.flags['F_CONTIGUOUS']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demonstrate contiguous vs non-contiguous in PyTorch\n",
    "tensor_2d = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "print(\"Original tensor:\")\n",
    "print(f\"  Shape:         {tensor_2d.shape}\")\n",
    "print(f\"  Stride:        {tensor_2d.stride()}\")\n",
    "print(f\"  Is contiguous: {tensor_2d.is_contiguous()}\")\n",
    "\n",
    "# Transpose creates a non-contiguous view (no data copy!)\n",
    "tensor_transposed = tensor_2d.T\n",
    "print(f\"\\nTransposed tensor (view, no copy):\")\n",
    "print(f\"  Shape:         {tensor_transposed.shape}\")\n",
    "print(f\"  Stride:        {tensor_transposed.stride()}\")\n",
    "print(f\"  Is contiguous: {tensor_transposed.is_contiguous()}\")\n",
    "\n",
    "# Making it contiguous creates a new copy with proper layout\n",
    "tensor_contiguous = tensor_transposed.contiguous()\n",
    "print(f\"\\nAfter .contiguous() (new copy):\")\n",
    "print(f\"  Shape:         {tensor_contiguous.shape}\")\n",
    "print(f\"  Stride:        {tensor_contiguous.stride()}\")\n",
    "print(f\"  Is contiguous: {tensor_contiguous.is_contiguous()}\")\n",
    "\n",
    "# Verify the data is the same\n",
    "print(f\"\\nData matches: {torch.equal(tensor_transposed, tensor_contiguous)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize memory layout\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Row-major layout\n",
    "row_major_data = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "flat_row = row_major_data.flatten()  # Row-major: [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "colors_row = ['#2196F3', '#2196F3', '#2196F3', '#FF9800', '#FF9800', '#FF9800']\n",
    "axes[0].barh(range(6), [1]*6, color=colors_row, edgecolor='black', linewidth=1.5)\n",
    "for idx, val in enumerate(flat_row):\n",
    "    axes[0].text(0.5, idx, str(val), ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "axes[0].set_yticks(range(6))\n",
    "axes[0].set_yticklabels([f'addr {i}' for i in range(6)])\n",
    "axes[0].set_title('Row-Major (C Order)\\nRow 0 = blue, Row 1 = orange', fontsize=12)\n",
    "axes[0].set_xlabel('Memory Address')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].set_xticks([])\n",
    "\n",
    "# Column-major layout\n",
    "flat_col = row_major_data.flatten('F')  # Column-major: [1, 4, 2, 5, 3, 6]\n",
    "colors_col = ['#2196F3', '#FF9800', '#2196F3', '#FF9800', '#2196F3', '#FF9800']\n",
    "axes[1].barh(range(6), [1]*6, color=colors_col, edgecolor='black', linewidth=1.5)\n",
    "for idx, val in enumerate(flat_col):\n",
    "    axes[1].text(0.5, idx, str(val), ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "axes[1].set_yticks(range(6))\n",
    "axes[1].set_yticklabels([f'addr {i}' for i in range(6)])\n",
    "axes[1].set_title('Column-Major (Fortran Order)\\nRow 0 = blue, Row 1 = orange', fontsize=12)\n",
    "axes[1].set_xlabel('Memory Address')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 \u2014 Putting It All Together\n",
    "\n",
    "We now build a reusable `BenchmarkSuite` class that standardizes timing methodology.\n",
    "Good benchmarking requires:\n",
    "\n",
    "1. **Warmup runs** \u2014 the first execution is often slower due to JIT compilation, cache loading, etc.\n",
    "2. **Multiple timed runs** \u2014 take the average (or median) to reduce variance.\n",
    "3. **High-resolution timer** \u2014 `time.perf_counter()` provides the best precision for short operations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def benchmark_function(\n",
    "    func: Callable,\n",
    "    num_warmup: int = NUM_WARMUP,\n",
    "    num_timed_runs: int = NUM_TIMED_RUNS,\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Benchmark a callable with warmup and multiple timed runs.\n",
    "\n",
    "    Args:\n",
    "        func: Callable that takes no arguments (use lambda or functools.partial).\n",
    "        num_warmup: Number of warmup executions before timing.\n",
    "        num_timed_runs: Number of timed executions to average.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with 'mean', 'min', 'max', and 'all_times' keys.\n",
    "    \"\"\"\n",
    "    # Warmup\n",
    "    for _ in range(num_warmup):\n",
    "        func()\n",
    "\n",
    "    # Timed runs\n",
    "    times: list[float] = []\n",
    "    for _ in range(num_timed_runs):\n",
    "        start_time = time.perf_counter()\n",
    "        func()\n",
    "        end_time = time.perf_counter()\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    return {\n",
    "        \"mean\": np.mean(times),\n",
    "        \"min\": np.min(times),\n",
    "        \"max\": np.max(times),\n",
    "        \"all_times\": times,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class BenchmarkSuite:\n",
    "    \"\"\"A reusable benchmarking harness for comparing operations.\n",
    "\n",
    "    Attributes:\n",
    "        tasks: List of (name, callable) pairs to benchmark.\n",
    "        results: DataFrame of timing results after running.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tasks: list[tuple[str, Callable]],\n",
    "        num_warmup: int = NUM_WARMUP,\n",
    "        num_timed_runs: int = NUM_TIMED_RUNS,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the benchmark suite.\n",
    "\n",
    "        Args:\n",
    "            tasks: List of (name, callable) pairs.\n",
    "            num_warmup: Number of warmup runs.\n",
    "            num_timed_runs: Number of timed runs.\n",
    "        \"\"\"\n",
    "        self.tasks = tasks\n",
    "        self.num_warmup = num_warmup\n",
    "        self.num_timed_runs = num_timed_runs\n",
    "        self.results: pd.DataFrame | None = None\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        \"\"\"Execute all benchmarks and return a results DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with columns: Name, Mean (s), Min (s), Max (s).\n",
    "        \"\"\"\n",
    "        rows: list[dict[str, object]] = []\n",
    "        for name, func in self.tasks:\n",
    "            timing = benchmark_function(func, self.num_warmup, self.num_timed_runs)\n",
    "            rows.append({\n",
    "                \"Name\": name,\n",
    "                \"Mean (s)\": timing[\"mean\"],\n",
    "                \"Min (s)\": timing[\"min\"],\n",
    "                \"Max (s)\": timing[\"max\"],\n",
    "            })\n",
    "        self.results = pd.DataFrame(rows)\n",
    "        return self.results\n",
    "\n",
    "    def plot_results(self, title: str = \"Benchmark Results\") -> None:\n",
    "        \"\"\"Plot benchmark results as a horizontal bar chart.\n",
    "\n",
    "        Args:\n",
    "            title: Title for the plot.\n",
    "        \"\"\"\n",
    "        if self.results is None:\n",
    "            raise ValueError(\"Run benchmarks first with .run()\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        names = self.results[\"Name\"]\n",
    "        means = self.results[\"Mean (s)\"]\n",
    "        colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(names)))\n",
    "\n",
    "        bars = ax.barh(range(len(names)), means, color=colors, edgecolor='black')\n",
    "        ax.set_yticks(range(len(names)))\n",
    "        ax.set_yticklabels(names)\n",
    "        ax.set_xlabel(\"Mean Time (seconds)\")\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # Add time labels on bars\n",
    "        for bar_item, mean_val in zip(bars, means):\n",
    "            ax.text(\n",
    "                bar_item.get_width() * 1.02,\n",
    "                bar_item.get_y() + bar_item.get_height() / 2,\n",
    "                f\"{mean_val:.6f}s\",\n",
    "                va='center',\n",
    "                fontsize=10,\n",
    "            )\n",
    "        ax.set_xlim(0, max(means) * 1.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sanity check: benchmark the three dot product implementations\n",
    "dot_tasks = [\n",
    "    (\"Python Loop\", lambda: python_dot_product(python_vec_a, python_vec_b)),\n",
    "    (\"NumPy\", lambda: numpy_dot_product(numpy_vec_a, numpy_vec_b)),\n",
    "    (\"PyTorch\", lambda: torch_dot_product(torch_vec_a, torch_vec_b)),\n",
    "]\n",
    "\n",
    "dot_suite = BenchmarkSuite(dot_tasks)\n",
    "dot_results = dot_suite.run()\n",
    "print(f\"Dot product benchmark (vector size = {DEMO_SIZE}):\")\n",
    "print(dot_results.to_string(index=False))\n",
    "dot_suite.plot_results(f\"Dot Product Benchmark (n={DEMO_SIZE})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 \u2014 Benchmarking Real ML Operations\n",
    "\n",
    "Now we systematically benchmark operations at increasing scales. This reveals:\n",
    "\n",
    "1. At what size does vectorization become essential?\n",
    "2. How does the speedup ratio grow with problem size?\n",
    "3. Where does PyTorch overhead exceed NumPy for small operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Vector Dot Product at Scale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def run_scaling_benchmark_dot(\n",
    "    sizes: list[int],\n",
    "    python_max_size: int = PYTHON_MAX_SIZE,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Benchmark dot product across Python, NumPy, and PyTorch at multiple sizes.\n",
    "\n",
    "    Args:\n",
    "        sizes: List of vector sizes to benchmark.\n",
    "        python_max_size: Maximum size to include Python loop benchmarks (too slow beyond).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with timing results for each approach and size.\n",
    "    \"\"\"\n",
    "    records: list[dict[str, object]] = []\n",
    "\n",
    "    for size in sizes:\n",
    "        print(f\"  Benchmarking size {size:>6d}...\", end=\"\")\n",
    "\n",
    "        # Generate data\n",
    "        py_a = [random.gauss(0, 1) for _ in range(size)]\n",
    "        py_b = [random.gauss(0, 1) for _ in range(size)]\n",
    "        np_a = np.array(py_a)\n",
    "        np_b = np.array(py_b)\n",
    "        pt_a = torch.tensor(py_a)\n",
    "        pt_b = torch.tensor(py_b)\n",
    "\n",
    "        # Python benchmark (skip for very large sizes)\n",
    "        if size <= python_max_size:\n",
    "            python_time = benchmark_function(lambda: python_dot_product(py_a, py_b))[\"mean\"]\n",
    "        else:\n",
    "            python_time = float(\"nan\")\n",
    "\n",
    "        # NumPy benchmark\n",
    "        numpy_time = benchmark_function(lambda: numpy_dot_product(np_a, np_b))[\"mean\"]\n",
    "\n",
    "        # PyTorch benchmark\n",
    "        torch_time = benchmark_function(lambda: torch_dot_product(pt_a, pt_b))[\"mean\"]\n",
    "\n",
    "        records.append({\n",
    "            \"Size\": size,\n",
    "            \"Python (s)\": python_time,\n",
    "            \"NumPy (s)\": numpy_time,\n",
    "            \"PyTorch (s)\": torch_time,\n",
    "        })\n",
    "        print(\" done\")\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "print(\"Running dot product scaling benchmark...\")\n",
    "dot_scaling_results = run_scaling_benchmark_dot(VECTOR_SIZES)\n",
    "print(\"\\nDot Product Scaling Results:\")\n",
    "print(dot_scaling_results.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Matrix Multiplication at Scale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def run_scaling_benchmark_matmul(\n",
    "    sizes: list[int],\n",
    "    python_max_size: int = 200,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Benchmark matrix multiplication across Python, NumPy, and PyTorch.\n",
    "\n",
    "    Args:\n",
    "        sizes: List of matrix dimensions (square matrices of size n x n).\n",
    "        python_max_size: Maximum matrix dimension for Python loop benchmarks.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with timing results for each approach and size.\n",
    "    \"\"\"\n",
    "    records: list[dict[str, object]] = []\n",
    "\n",
    "    for size in sizes:\n",
    "        print(f\"  Benchmarking {size}x{size} matrix multiply...\", end=\"\")\n",
    "\n",
    "        # Generate data\n",
    "        np_a = np.random.randn(size, size)\n",
    "        np_b = np.random.randn(size, size)\n",
    "        pt_a = torch.tensor(np_a)\n",
    "        pt_b = torch.tensor(np_b)\n",
    "\n",
    "        # Python benchmark (skip for large sizes - O(n^3) is very slow)\n",
    "        if size <= python_max_size:\n",
    "            py_a = np_a.tolist()\n",
    "            py_b = np_b.tolist()\n",
    "            python_time = benchmark_function(lambda: python_matmul(py_a, py_b))[\"mean\"]\n",
    "        else:\n",
    "            python_time = float(\"nan\")\n",
    "\n",
    "        # NumPy benchmark\n",
    "        numpy_time = benchmark_function(lambda: numpy_matmul(np_a, np_b))[\"mean\"]\n",
    "\n",
    "        # PyTorch benchmark\n",
    "        torch_time = benchmark_function(lambda: torch_matmul(pt_a, pt_b))[\"mean\"]\n",
    "\n",
    "        # Verify NumPy and PyTorch produce the same result\n",
    "        np_result = numpy_matmul(np_a, np_b)\n",
    "        pt_result = torch_matmul(pt_a, pt_b).numpy()\n",
    "        assert np.allclose(np_result, pt_result, atol=1e-6), (\n",
    "            f\"NumPy and PyTorch disagree at size {size}\"\n",
    "        )\n",
    "\n",
    "        records.append({\n",
    "            \"Size\": f\"{size}x{size}\",\n",
    "            \"Python (s)\": python_time,\n",
    "            \"NumPy (s)\": numpy_time,\n",
    "            \"PyTorch (s)\": torch_time,\n",
    "        })\n",
    "        print(\" done\")\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "print(\"Running matrix multiplication scaling benchmark...\")\n",
    "matmul_scaling_results = run_scaling_benchmark_matmul(MATRIX_SIZES)\n",
    "print(\"\\nMatrix Multiplication Scaling Results:\")\n",
    "print(matmul_scaling_results.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Element-wise Operations at Scale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def run_scaling_benchmark_elementwise(\n",
    "    sizes: list[int],\n",
    "    python_max_size: int = PYTHON_MAX_SIZE,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Benchmark element-wise multiplication across Python, NumPy, and PyTorch.\n",
    "\n",
    "    Args:\n",
    "        sizes: List of vector sizes to benchmark.\n",
    "        python_max_size: Maximum size for Python loop benchmarks.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with timing results for each approach and size.\n",
    "    \"\"\"\n",
    "    records: list[dict[str, object]] = []\n",
    "\n",
    "    for size in sizes:\n",
    "        print(f\"  Benchmarking element-wise multiply, size {size:>6d}...\", end=\"\")\n",
    "\n",
    "        py_a = [random.gauss(0, 1) for _ in range(size)]\n",
    "        py_b = [random.gauss(0, 1) for _ in range(size)]\n",
    "        np_a = np.array(py_a)\n",
    "        np_b = np.array(py_b)\n",
    "        pt_a = torch.tensor(py_a)\n",
    "        pt_b = torch.tensor(py_b)\n",
    "\n",
    "        if size <= python_max_size:\n",
    "            python_time = benchmark_function(\n",
    "                lambda: python_elementwise_multiply(py_a, py_b)\n",
    "            )[\"mean\"]\n",
    "        else:\n",
    "            python_time = float(\"nan\")\n",
    "\n",
    "        numpy_time = benchmark_function(\n",
    "            lambda: numpy_elementwise_multiply(np_a, np_b)\n",
    "        )[\"mean\"]\n",
    "\n",
    "        torch_time = benchmark_function(\n",
    "            lambda: torch_elementwise_multiply(pt_a, pt_b)\n",
    "        )[\"mean\"]\n",
    "\n",
    "        records.append({\n",
    "            \"Size\": size,\n",
    "            \"Python (s)\": python_time,\n",
    "            \"NumPy (s)\": numpy_time,\n",
    "            \"PyTorch (s)\": torch_time,\n",
    "        })\n",
    "        print(\" done\")\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "print(\"Running element-wise multiply scaling benchmark...\")\n",
    "elemwise_scaling_results = run_scaling_benchmark_elementwise(VECTOR_SIZES)\n",
    "print(\"\\nElement-wise Multiply Scaling Results:\")\n",
    "print(elemwise_scaling_results.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Computing Speedup Ratios"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_speedup_table(results_df: pd.DataFrame, operation_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Compute speedup ratios relative to Python for a benchmark results table.\n",
    "\n",
    "    Args:\n",
    "        results_df: DataFrame with 'Size', 'Python (s)', 'NumPy (s)', 'PyTorch (s)' columns.\n",
    "        operation_name: Name of the operation for display.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with speedup ratios added.\n",
    "    \"\"\"\n",
    "    speedup_df = results_df.copy()\n",
    "\n",
    "    # Compute speedup ratios where Python time is available\n",
    "    python_times = speedup_df[\"Python (s)\"]\n",
    "    numpy_times = speedup_df[\"NumPy (s)\"]\n",
    "    torch_times = speedup_df[\"PyTorch (s)\"]\n",
    "\n",
    "    speedup_df[\"NumPy vs Python\"] = python_times / numpy_times\n",
    "    speedup_df[\"PyTorch vs Python\"] = python_times / torch_times\n",
    "    speedup_df[\"NumPy vs PyTorch\"] = torch_times / numpy_times\n",
    "\n",
    "    return speedup_df\n",
    "\n",
    "\n",
    "# Compute speedups for dot product\n",
    "dot_speedup = compute_speedup_table(dot_scaling_results, \"Dot Product\")\n",
    "print(\"Dot Product Speedups:\")\n",
    "print(dot_speedup.to_string(index=False, float_format=\"{:.2f}\".format))\n",
    "\n",
    "print(\"\\nElement-wise Multiply Speedups:\")\n",
    "elemwise_speedup = compute_speedup_table(elemwise_scaling_results, \"Element-wise Multiply\")\n",
    "print(elemwise_speedup.to_string(index=False, float_format=\"{:.2f}\".format))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Broadcasting Performance: Loops vs Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_bias_python_loop(\n",
    "    data: list[list[float]], bias: list[float]\n",
    ") -> list[list[float]]:\n",
    "    \"\"\"Add a bias vector to each row of a data matrix using Python loops.\n",
    "\n",
    "    Args:\n",
    "        data: Matrix as a list of lists, shape (num_samples, num_features).\n",
    "        bias: Bias vector as a list, shape (num_features,).\n",
    "\n",
    "    Returns:\n",
    "        Result matrix with bias added to each row.\n",
    "    \"\"\"\n",
    "    num_samples = len(data)\n",
    "    num_features = len(data[0])\n",
    "    result = [[0.0] * num_features for _ in range(num_samples)]\n",
    "    for row_idx in range(num_samples):\n",
    "        for col_idx in range(num_features):\n",
    "            result[row_idx][col_idx] = data[row_idx][col_idx] + bias[col_idx]\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_bias_numpy_broadcast(\n",
    "    data: np.ndarray, bias: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Add a bias vector using NumPy broadcasting.\n",
    "\n",
    "    Args:\n",
    "        data: Matrix of shape (num_samples, num_features).\n",
    "        bias: Bias vector of shape (num_features,).\n",
    "\n",
    "    Returns:\n",
    "        Result array with bias added.\n",
    "    \"\"\"\n",
    "    return data + bias\n",
    "\n",
    "\n",
    "def add_bias_torch_broadcast(\n",
    "    data: torch.Tensor, bias: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Add a bias vector using PyTorch broadcasting.\n",
    "\n",
    "    Args:\n",
    "        data: Tensor of shape (num_samples, num_features).\n",
    "        bias: Bias tensor of shape (num_features,).\n",
    "\n",
    "    Returns:\n",
    "        Result tensor with bias added.\n",
    "    \"\"\"\n",
    "    return data + bias\n",
    "\n",
    "\n",
    "# Benchmark broadcasting: add bias to 1000 samples x 500 features\n",
    "broadcast_num_samples = 1000\n",
    "broadcast_num_features = 500\n",
    "\n",
    "np_data = np.random.randn(broadcast_num_samples, broadcast_num_features)\n",
    "np_bias = np.random.randn(broadcast_num_features)\n",
    "py_data = np_data.tolist()\n",
    "py_bias = np_bias.tolist()\n",
    "pt_data = torch.tensor(np_data)\n",
    "pt_bias = torch.tensor(np_bias)\n",
    "\n",
    "broadcast_tasks = [\n",
    "    (\"Python Loops\", lambda: add_bias_python_loop(py_data, py_bias)),\n",
    "    (\"NumPy Broadcasting\", lambda: add_bias_numpy_broadcast(np_data, np_bias)),\n",
    "    (\"PyTorch Broadcasting\", lambda: add_bias_torch_broadcast(pt_data, pt_bias)),\n",
    "]\n",
    "\n",
    "broadcast_suite = BenchmarkSuite(broadcast_tasks)\n",
    "broadcast_results = broadcast_suite.run()\n",
    "print(f\"Broadcasting Benchmark ({broadcast_num_samples} samples x {broadcast_num_features} features):\")\n",
    "print(broadcast_results.to_string(index=False))\n",
    "\n",
    "python_broadcast_time = float(broadcast_results.loc[0, \"Mean (s)\"])\n",
    "numpy_broadcast_time = float(broadcast_results.loc[1, \"Mean (s)\"])\n",
    "torch_broadcast_time = float(broadcast_results.loc[2, \"Mean (s)\"])\n",
    "\n",
    "print(f\"\\nSpeedup: NumPy is {python_broadcast_time / numpy_broadcast_time:.2f}x faster than Python\")\n",
    "print(f\"Speedup: PyTorch is {python_broadcast_time / torch_broadcast_time:.2f}x faster than Python\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4 \u2014 Evaluation & Analysis\n",
    "\n",
    "We now visualize and analyze the benchmark results to understand the full picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Speedup Curves (Log Scale)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_scaling_comparison(\n",
    "    results_df: pd.DataFrame,\n",
    "    title: str,\n",
    "    size_column: str = \"Size\",\n",
    ") -> None:\n",
    "    \"\"\"Plot timing results on a log scale for all three implementations.\n",
    "\n",
    "    Args:\n",
    "        results_df: DataFrame with timing results.\n",
    "        title: Plot title.\n",
    "        size_column: Column name for the x-axis (problem size).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    sizes = results_df[size_column]\n",
    "\n",
    "    # Convert sizes to numeric if they are strings like \"50x50\"\n",
    "    if isinstance(sizes.iloc[0], str):\n",
    "        numeric_sizes = [int(s.split('x')[0]) for s in sizes]\n",
    "    else:\n",
    "        numeric_sizes = sizes.tolist()\n",
    "\n",
    "    # Left plot: Absolute times (log scale)\n",
    "    python_times = results_df[\"Python (s)\"]\n",
    "    numpy_times = results_df[\"NumPy (s)\"]\n",
    "    torch_times = results_df[\"PyTorch (s)\"]\n",
    "\n",
    "    # Only plot Python where it was measured\n",
    "    valid_python_mask = ~python_times.isna()\n",
    "    if valid_python_mask.any():\n",
    "        axes[0].plot(\n",
    "            [numeric_sizes[i] for i in range(len(numeric_sizes)) if valid_python_mask.iloc[i]],\n",
    "            python_times[valid_python_mask],\n",
    "            'o-', label='Python Loop', color='#E53935', linewidth=2, markersize=7,\n",
    "        )\n",
    "\n",
    "    axes[0].plot(numeric_sizes, numpy_times, 's-', label='NumPy', color='#1E88E5',\n",
    "                 linewidth=2, markersize=7)\n",
    "    axes[0].plot(numeric_sizes, torch_times, '^-', label='PyTorch', color='#43A047',\n",
    "                 linewidth=2, markersize=7)\n",
    "\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_yscale('log')\n",
    "    axes[0].set_xlabel('Problem Size')\n",
    "    axes[0].set_ylabel('Time (seconds, log scale)')\n",
    "    axes[0].set_title(f'{title} \\u2014 Absolute Times')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Right plot: Speedup ratios\n",
    "    if valid_python_mask.any():\n",
    "        valid_sizes = [numeric_sizes[i] for i in range(len(numeric_sizes)) if valid_python_mask.iloc[i]]\n",
    "        numpy_speedup = (python_times[valid_python_mask] / numpy_times[valid_python_mask]).tolist()\n",
    "        torch_speedup = (python_times[valid_python_mask] / torch_times[valid_python_mask]).tolist()\n",
    "\n",
    "        axes[1].plot(valid_sizes, numpy_speedup, 's-', label='NumPy vs Python',\n",
    "                     color='#1E88E5', linewidth=2, markersize=7)\n",
    "        axes[1].plot(valid_sizes, torch_speedup, '^-', label='PyTorch vs Python',\n",
    "                     color='#43A047', linewidth=2, markersize=7)\n",
    "        axes[1].axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='No speedup')\n",
    "\n",
    "        axes[1].set_xscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "        axes[1].set_xlabel('Problem Size')\n",
    "        axes[1].set_ylabel('Speedup (x times faster)')\n",
    "        axes[1].set_title(f'{title} \\u2014 Speedup vs Python')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_scaling_comparison(dot_scaling_results, \"Dot Product\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_scaling_comparison(elemwise_scaling_results, \"Element-wise Multiply\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_scaling_comparison(matmul_scaling_results, \"Matrix Multiplication\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Comprehensive Comparison DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_comprehensive_table(\n",
    "    dot_results: pd.DataFrame,\n",
    "    elemwise_results: pd.DataFrame,\n",
    "    matmul_results: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a comprehensive comparison table for all operations and sizes.\n",
    "\n",
    "    Args:\n",
    "        dot_results: Dot product benchmark results.\n",
    "        elemwise_results: Element-wise multiply benchmark results.\n",
    "        matmul_results: Matrix multiply benchmark results.\n",
    "\n",
    "    Returns:\n",
    "        Combined DataFrame with all results and speedups.\n",
    "    \"\"\"\n",
    "    rows: list[dict[str, object]] = []\n",
    "\n",
    "    # Dot product rows\n",
    "    for _, row in dot_results.iterrows():\n",
    "        python_time = row[\"Python (s)\"]\n",
    "        numpy_time = row[\"NumPy (s)\"]\n",
    "        torch_time = row[\"PyTorch (s)\"]\n",
    "        numpy_speedup = python_time / numpy_time if not np.isnan(python_time) else float(\"nan\")\n",
    "        rows.append({\n",
    "            \"Operation\": \"Dot Product\",\n",
    "            \"Size\": row[\"Size\"],\n",
    "            \"Python (s)\": f\"{python_time:.6f}\" if not np.isnan(python_time) else \"N/A\",\n",
    "            \"NumPy (s)\": f\"{numpy_time:.6f}\",\n",
    "            \"PyTorch (s)\": f\"{torch_time:.6f}\",\n",
    "            \"NumPy Speedup\": f\"{numpy_speedup:.2f}x\" if not np.isnan(numpy_speedup) else \"N/A\",\n",
    "        })\n",
    "\n",
    "    # Element-wise rows\n",
    "    for _, row in elemwise_results.iterrows():\n",
    "        python_time = row[\"Python (s)\"]\n",
    "        numpy_time = row[\"NumPy (s)\"]\n",
    "        torch_time = row[\"PyTorch (s)\"]\n",
    "        numpy_speedup = python_time / numpy_time if not np.isnan(python_time) else float(\"nan\")\n",
    "        rows.append({\n",
    "            \"Operation\": \"Elem-wise Multiply\",\n",
    "            \"Size\": row[\"Size\"],\n",
    "            \"Python (s)\": f\"{python_time:.6f}\" if not np.isnan(python_time) else \"N/A\",\n",
    "            \"NumPy (s)\": f\"{numpy_time:.6f}\",\n",
    "            \"PyTorch (s)\": f\"{torch_time:.6f}\",\n",
    "            \"NumPy Speedup\": f\"{numpy_speedup:.2f}x\" if not np.isnan(numpy_speedup) else \"N/A\",\n",
    "        })\n",
    "\n",
    "    # Matmul rows\n",
    "    for _, row in matmul_results.iterrows():\n",
    "        python_time = row[\"Python (s)\"]\n",
    "        numpy_time = row[\"NumPy (s)\"]\n",
    "        torch_time = row[\"PyTorch (s)\"]\n",
    "        numpy_speedup = python_time / numpy_time if not np.isnan(python_time) else float(\"nan\")\n",
    "        rows.append({\n",
    "            \"Operation\": \"Matrix Multiply\",\n",
    "            \"Size\": row[\"Size\"],\n",
    "            \"Python (s)\": f\"{python_time:.6f}\" if not np.isnan(python_time) else \"N/A\",\n",
    "            \"NumPy (s)\": f\"{numpy_time:.6f}\",\n",
    "            \"PyTorch (s)\": f\"{torch_time:.6f}\",\n",
    "            \"NumPy Speedup\": f\"{numpy_speedup:.2f}x\" if not np.isnan(numpy_speedup) else \"N/A\",\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "comprehensive_table = build_comprehensive_table(\n",
    "    dot_scaling_results, elemwise_scaling_results, matmul_scaling_results\n",
    ")\n",
    "print(\"Comprehensive Benchmark Results:\")\n",
    "print(comprehensive_table.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 PyTorch Overhead Analysis\n",
    "\n",
    "For very small arrays, PyTorch can actually be *slower* than NumPy due to:\n",
    "\n",
    "1. **Tensor creation overhead** \u2014 PyTorch allocates memory through its own allocator\n",
    "2. **Dispatch overhead** \u2014 PyTorch routes operations through a dispatcher that checks for autograd, device type, etc.\n",
    "3. **Autograd bookkeeping** \u2014 even when not computing gradients, the system checks whether it should\n",
    "\n",
    "Let us quantify this crossover point."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def benchmark_overhead_crossover(sizes: list[int]) -> pd.DataFrame:\n",
    "    \"\"\"Find the size where PyTorch becomes faster than NumPy for dot product.\n",
    "\n",
    "    Args:\n",
    "        sizes: List of vector sizes to test.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame comparing NumPy and PyTorch times at each size.\n",
    "    \"\"\"\n",
    "    records: list[dict[str, object]] = []\n",
    "\n",
    "    for size in sizes:\n",
    "        np_a = np.random.randn(size)\n",
    "        np_b = np.random.randn(size)\n",
    "        pt_a = torch.tensor(np_a)\n",
    "        pt_b = torch.tensor(np_b)\n",
    "\n",
    "        numpy_time = benchmark_function(lambda: np.dot(np_a, np_b), num_timed_runs=10)[\"mean\"]\n",
    "        torch_time = benchmark_function(lambda: torch.dot(pt_a, pt_b), num_timed_runs=10)[\"mean\"]\n",
    "\n",
    "        records.append({\n",
    "            \"Size\": size,\n",
    "            \"NumPy (s)\": numpy_time,\n",
    "            \"PyTorch (s)\": torch_time,\n",
    "            \"Ratio (PT/NP)\": torch_time / numpy_time,\n",
    "            \"Faster\": \"NumPy\" if numpy_time < torch_time else \"PyTorch\",\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "overhead_sizes = [10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "overhead_results = benchmark_overhead_crossover(overhead_sizes)\n",
    "print(\"NumPy vs PyTorch Overhead Crossover:\")\n",
    "print(overhead_results.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize the overhead crossover\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(overhead_results[\"Size\"], overhead_results[\"NumPy (s)\"],\n",
    "        's-', label='NumPy', color='#1E88E5', linewidth=2, markersize=7)\n",
    "ax.plot(overhead_results[\"Size\"], overhead_results[\"PyTorch (s)\"],\n",
    "        '^-', label='PyTorch', color='#43A047', linewidth=2, markersize=7)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Vector Size')\n",
    "ax.set_ylabel('Time (seconds, log scale)')\n",
    "ax.set_title('NumPy vs PyTorch: Overhead Crossover for Dot Product')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Memory Layout Performance Impact"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def benchmark_contiguous_vs_noncontiguous(matrix_size: int) -> pd.DataFrame:\n",
    "    \"\"\"Benchmark operations on contiguous vs non-contiguous tensors.\n",
    "\n",
    "    Args:\n",
    "        matrix_size: Size of square matrix (n x n).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with timing results.\n",
    "    \"\"\"\n",
    "    # Create a contiguous tensor\n",
    "    contiguous_tensor = torch.randn(matrix_size, matrix_size)\n",
    "    assert contiguous_tensor.is_contiguous(), \"Should be contiguous\"\n",
    "\n",
    "    # Create a non-contiguous view via transpose\n",
    "    noncontiguous_tensor = contiguous_tensor.T\n",
    "    assert not noncontiguous_tensor.is_contiguous(), \"Transpose should be non-contiguous\"\n",
    "\n",
    "    # Benchmark sum operation on both\n",
    "    contiguous_time = benchmark_function(\n",
    "        lambda: contiguous_tensor.sum(), num_timed_runs=10\n",
    "    )[\"mean\"]\n",
    "    noncontiguous_time = benchmark_function(\n",
    "        lambda: noncontiguous_tensor.sum(), num_timed_runs=10\n",
    "    )[\"mean\"]\n",
    "\n",
    "    # Benchmark matrix multiply\n",
    "    other_matrix = torch.randn(matrix_size, matrix_size)\n",
    "    contiguous_matmul_time = benchmark_function(\n",
    "        lambda: torch.matmul(contiguous_tensor, other_matrix), num_timed_runs=10\n",
    "    )[\"mean\"]\n",
    "    noncontiguous_matmul_time = benchmark_function(\n",
    "        lambda: torch.matmul(noncontiguous_tensor, other_matrix), num_timed_runs=10\n",
    "    )[\"mean\"]\n",
    "\n",
    "    return pd.DataFrame([\n",
    "        {\"Operation\": \"Sum\", \"Contiguous (s)\": contiguous_time,\n",
    "         \"Non-contiguous (s)\": noncontiguous_time,\n",
    "         \"Slowdown\": noncontiguous_time / contiguous_time},\n",
    "        {\"Operation\": \"MatMul\", \"Contiguous (s)\": contiguous_matmul_time,\n",
    "         \"Non-contiguous (s)\": noncontiguous_matmul_time,\n",
    "         \"Slowdown\": noncontiguous_matmul_time / contiguous_matmul_time},\n",
    "    ])\n",
    "\n",
    "\n",
    "contiguity_size = 1000\n",
    "contiguity_results = benchmark_contiguous_vs_noncontiguous(contiguity_size)\n",
    "print(f\"Contiguous vs Non-contiguous Performance ({contiguity_size}x{contiguity_size} matrix):\")\n",
    "print(contiguity_results.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize contiguity impact\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "operations = contiguity_results[\"Operation\"]\n",
    "contiguous_times = contiguity_results[\"Contiguous (s)\"]\n",
    "noncontiguous_times = contiguity_results[\"Non-contiguous (s)\"]\n",
    "\n",
    "x_positions = np.arange(len(operations))\n",
    "bar_width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x_positions - bar_width / 2, contiguous_times,\n",
    "               bar_width, label='Contiguous', color='#1E88E5', edgecolor='black')\n",
    "bars2 = ax.bar(x_positions + bar_width / 2, noncontiguous_times,\n",
    "               bar_width, label='Non-contiguous', color='#FF9800', edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title(f'Contiguous vs Non-contiguous Tensor Performance\\n({contiguity_size}x{contiguity_size} matrix)')\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(operations)\n",
    "ax.legend()\n",
    "\n",
    "# Add slowdown labels\n",
    "for idx, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "    slowdown = float(contiguity_results.iloc[idx][\"Slowdown\"])\n",
    "    ax.text(bar2.get_x() + bar2.get_width() / 2, bar2.get_height() * 1.02,\n",
    "            f'{slowdown:.2f}x', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Summary Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_speedup_summary(dot_df: pd.DataFrame, elemwise_df: pd.DataFrame) -> None:\n",
    "    \"\"\"Plot a summary of speedups across operations and sizes.\n",
    "\n",
    "    Args:\n",
    "        dot_df: Dot product scaling results.\n",
    "        elemwise_df: Element-wise multiply scaling results.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Filter to sizes where Python was benchmarked\n",
    "    dot_valid = dot_df[~dot_df[\"Python (s)\"].isna()]\n",
    "    elem_valid = elemwise_df[~elemwise_df[\"Python (s)\"].isna()]\n",
    "\n",
    "    # Dot product speedups\n",
    "    if len(dot_valid) > 0:\n",
    "        numpy_speedup = dot_valid[\"Python (s)\"] / dot_valid[\"NumPy (s)\"]\n",
    "        torch_speedup = dot_valid[\"Python (s)\"] / dot_valid[\"PyTorch (s)\"]\n",
    "        sizes = dot_valid[\"Size\"]\n",
    "\n",
    "        axes[0].bar(np.arange(len(sizes)) - 0.2, numpy_speedup, 0.4,\n",
    "                    label='NumPy vs Python', color='#1E88E5', edgecolor='black')\n",
    "        axes[0].bar(np.arange(len(sizes)) + 0.2, torch_speedup, 0.4,\n",
    "                    label='PyTorch vs Python', color='#43A047', edgecolor='black')\n",
    "        axes[0].set_xticks(np.arange(len(sizes)))\n",
    "        axes[0].set_xticklabels([str(s) for s in sizes], rotation=45)\n",
    "        axes[0].set_xlabel('Vector Size')\n",
    "        axes[0].set_ylabel('Speedup (x times faster)')\n",
    "        axes[0].set_title('Dot Product Speedup')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Element-wise speedups\n",
    "    if len(elem_valid) > 0:\n",
    "        numpy_speedup = elem_valid[\"Python (s)\"] / elem_valid[\"NumPy (s)\"]\n",
    "        torch_speedup = elem_valid[\"Python (s)\"] / elem_valid[\"PyTorch (s)\"]\n",
    "        sizes = elem_valid[\"Size\"]\n",
    "\n",
    "        axes[1].bar(np.arange(len(sizes)) - 0.2, numpy_speedup, 0.4,\n",
    "                    label='NumPy vs Python', color='#1E88E5', edgecolor='black')\n",
    "        axes[1].bar(np.arange(len(sizes)) + 0.2, torch_speedup, 0.4,\n",
    "                    label='PyTorch vs Python', color='#43A047', edgecolor='black')\n",
    "        axes[1].set_xticks(np.arange(len(sizes)))\n",
    "        axes[1].set_xticklabels([str(s) for s in sizes], rotation=45)\n",
    "        axes[1].set_xlabel('Vector Size')\n",
    "        axes[1].set_ylabel('Speedup (x times faster)')\n",
    "        axes[1].set_title('Element-wise Multiply Speedup')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_speedup_summary(dot_scaling_results, elemwise_scaling_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Broadcasting benchmark plot\n",
    "broadcast_suite.plot_results(\n",
    "    f\"Broadcasting: Add Bias ({broadcast_num_samples} samples x {broadcast_num_features} features)\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5 \u2014 Summary & Lessons Learned\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Vectorized operations are 10-1000x faster than Python loops** for numerical computation. The speedup grows with problem size because vectorized libraries amortize their fixed overhead (dispatch, memory allocation) across more useful work.\n",
    "\n",
    "2. **NumPy and PyTorch produce numerically identical results** but have different performance profiles. NumPy has lower overhead for small arrays, while PyTorch matches or exceeds NumPy at larger sizes and adds GPU support.\n",
    "\n",
    "3. **Broadcasting eliminates the need for explicit loops** when combining arrays of different shapes. The three broadcasting rules (pad with 1s, stretch size-1 dims, fail if incompatible) apply identically in both NumPy and PyTorch.\n",
    "\n",
    "4. **Memory layout (contiguous, strided) affects performance.** Understanding strides and contiguity prevents subtle bugs (e.g., passing a non-contiguous tensor to an operation that requires contiguous memory) and helps you reason about cache efficiency.\n",
    "\n",
    "5. **PyTorch tensors share NumPy's API but add GPU support and autograd.** The autograd system (covered in Module 5) automatically computes gradients through all tensor operations, enabling neural network training.\n",
    "\n",
    "### What's Next\n",
    "\n",
    "**1-02 (Advanced NumPy & PyTorch Operations)** builds on the tensor foundations established here with reshape, view, transpose, einsum notation, and advanced indexing \u2014 the manipulation operations you will use in every notebook from here forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}